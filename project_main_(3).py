# -*- coding: utf-8 -*-
"""Project_main (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nULaaHR-_6kNZK8G-7868-oiNDcGKPy6

# TOP 50 Cryptocurrencies Historical Prices
**Nikulin Maxim DSBA 243-2**

***Introduction:***
The cryptocurrency market has evolved dramatically in recent years, with the total market capitalization reaching $3.46 trillion as of 2024 . This analysis focuses on examining the historical price movements and market trends of the top 50 cryptocurrencies, providing valuable insights into the digital asset ecosystem's development and dynamics.

The data of this dataset can be found by following link: https://www.kaggle.com/datasets/odins0n/top-50-cryptocurrency-historical-prices?resource=download

***Dataset description:***
- Date: Date of observation
- Price: Price on the given day (Also the closing price for that day)
- Open: Opening price on the given day
- High: Highest price on the given day
- Low: Lowest price on the given day
- Volume: Volume of transactions on the given day
- Change%: Percentage Change from the previous day


***Main part:***

Importing main libraries to our project:
"""

import pandas as pd
import numpy as np
import plotly.express as px
import plotly.io as pio
import plotly.graph_objects as go
import plotly.io as pio
from IPython.display import HTML
from plotly.subplots import make_subplots
import kaleido

"""This is the heading of the dataset:"""

df = pd.read_csv(r'C:\Users\m4xni\Desktop\Проекты\HSE_project\Nikulin_243_2\Aave.csv')
print(df.head(10))

"""**1. In our project all columns are numeric. So, let's find:**
- Medival values,
- Avarage values,
- Standard deviation of fields.
"""

print("\033[1mMedian values:\033[0m")
print((df[['Price', 'Open', 'High', 'Low', 'Vol.', 'Change %']].median()).round(2))
print()

print("\033[1mMean values:\033[0m")
print((df[['Price', 'Open', 'High', 'Low', 'Vol.', 'Change %']].mean()).round(2))
print()

print("\033[1mStandart devitation values:\033[0m")
print((df[['Price', 'Open', 'High', 'Low', 'Vol.', 'Change %']].std()).round(2))
print()

"""**2. Let's check rows with NaN values:**"""

print(df.describe())

df = df.drop_duplicates()

"""We see that all types are correct and no null values were found, so data is clean

**3. Now we can create some graphs, which are based on our dataset**

For the easiest way to analyze data I prefer to take first 50 elements of currencies
"""

df['Date'] = pd.to_datetime(df['Date'])
df_50 = df.head(50).copy()
df_50['Timestamp'] = df_50['Date'].map(pd.Timestamp.timestamp)
x_50 = df_50['Timestamp']
y_50 = df_50['Price']
coefficients_50 = np.polyfit(x_50, y_50, 1)
trend_line_50 = np.poly1d(coefficients_50)
fig = px.line(
    df_50,
    x='Date',
    y='Price',
    labels={'Date': 'Date', 'Price': 'Price (USD)'}
)
fig.add_scatter(
    x=df_50['Date'],
    y=trend_line_50(x_50),
    mode='lines',
    name='Trend Line',
    line=dict(color='red', dash='dash')
)
fig.add_scatter(
    x=df_50['Date'],
    y=df_50['High'],
    mode='markers',
    name='High',
    marker=dict(color='green', size=8)
)
fig.add_scatter(
    x=df_50['Date'],
    y=df_50['Low'],
    mode='markers',
    name='Low',
    marker=dict(color='red', size=8)
)
fig.update_layout(
    xaxis_title='Date',
    yaxis_title='Price (USD)',
    template='plotly_white',
    title_x=0.5,
    width=1000,
    height=600
)
fig.show()

"""Analyzing this graph it can be seen that from 2018-02-01 to 2018-03-22 there was a decrease in prices of Krypto currences. Also there is a scatter diagram which shows higest price(green) and the lowest price(red) in particular data

Now, let's create bar chart
"""

df['Date'] = pd.to_datetime(df['Date'])
df_50 = df.head(50).copy()
fig = px.bar(
    df_50,
    x='Date',
    y=['Price', 'High', 'Low'],
    labels={'Date': 'Date', 'value': 'Price (USD)', 'variable': 'Metrics'},
    barmode='group'
)
fig.update_layout(
    title = 'Bar chart',
    xaxis_title='Date',
    yaxis_title='Price (USD)',
    template='plotly_white',
    title_x=0.5,
    width=1000,
    height=600
)
fig.show()

"""By looking at the chart, you can identify patterns or trends, such as whether the price remains stable or fluctuates significantly between High and Low values over the selected timeframe.
For any given date, the High bar will always be above or equal to Price, and Low will be below or equal to Price.
"""

df['Date'] = pd.to_datetime(df['Date'])
df_50 = df.head(50).copy()
fig = go.Figure()
fig.add_trace(go.Candlestick(
    x=df_50['Date'],  # Dates for the x-axis
    open=df_50['Change %'],  # Change as opening values
    high=df_50['Change %'] + df_50['Vol.'],  # Change + Vol. as high
    low=df_50['Change %'] - df_50['Vol.'],  # Change - Vol. as low
    close=df_50['Change %'],  # Change as closing values
    increasing_line_color='green',  # Color for increasing candles
    decreasing_line_color='red',  # Color for decreasing candles
    name='Candlestick (Vol. & Change)'
))
fig.update_layout(
    title = 'Candlestick chart',
    xaxis_title='Date',
    yaxis_title='Change & Volume',
    template='plotly_white',
    title_x=0.5,
    width=1000,
    height=600
)
fig.show()

"""**X-Axis (Dates):**
The horizontal axis shows the dates, representing the time period covered by the first 50 data points in chronological order.
This allows tracking changes and volumes over specific time intervals.


**Y-Axis (Change & Volume):**
The vertical axis represents the Change and its fluctuation influenced by Vol.
Positive and negative values of Change are visualized, with Vol. determining the range for each candlestick.
Candlestick Components:

**Open & Close (Change):**
The candlestick's body represents the Change value during the specified period.


**High & Low (Vol.):**
The wicks (lines above and below the body) show the maximum and minimum values of Change, calculated using Vol.:
High = Change + Vol.
Low = Change - Vol.


**Colors:**
Green Candlesticks: Represent an increase or no change during the time period.
Red Candlesticks: Indicate a decrease in value during the time period.

**Insights:**
This chart provides a visual representation of the volatility in Change influenced by the Vol. parameter.
It can help identify periods of high fluctuation (large candlesticks) or stability (small candlesticks).
"""

df['Date'] = pd.to_datetime(df['Date'])
df_50 = df.head(50).copy()
fig = go.Figure()
fig.add_trace(go.Scatter(
    x=df_50['Date'],
    y=df_50['High'],
    mode='lines',
    line=dict(color='green', width=1),
    name='High'
))
fig.add_trace(go.Scatter(
    x=df_50['Date'],
    y=df_50['Low'],
    mode='lines',
    line=dict(color='red', width=1),
    name='Low'
))
fig.add_trace(go.Scatter(
    x=df_50['Date'],
    y=df_50['Open'],
    mode='markers',
    marker=dict(color='blue', size=6),
    name='Open'
))
fig.update_layout(
    title='OHLC Chart',
    xaxis_title='Date',
    yaxis_title='Price (USD)',
    template='plotly_white',
    title_x=0.5,
    width=1000,
    height=600
)
fig.show()

"""The green line represents the highest price achieved during each time interval, while the red line shows the lowest price. The blue markers indicate the starting prices, providing a point of reference for each interval's price movements.

Periods with larger gaps between the green and red lines indicate high volatility, reflecting significant fluctuations in price during those intervals. Conversely, narrower gaps suggest stability with minimal price movement. The blue markers often align closer to either the green or red lines, reflecting whether the price trend was predominantly upward or downward.

This visualization captures short-term price behavior, showing trends of increase or decrease over time. Steep divergences between high and low values may indicate impactful market events or increased trading activity, while closely aligned lines suggest quieter market conditions. The chart serves as a concise tool for identifying trends and assessing market volatility within the selected period.

"""

x_col = 'High'
y_col = 'Low'
z_col = 'Change %'
data_50 = df.head(50)
# Group by to aggregate duplicates (if any)
data_grouped = data_50.groupby([y_col, x_col], as_index=False)[z_col].mean()
heatmap_data = data_grouped.pivot(index=y_col, columns=x_col, values=z_col)
fig = px.imshow(
    heatmap_data,
    color_continuous_scale="RdBu",
    zmin=heatmap_data.min().min(),
    zmax=heatmap_data.max().max(),
    title="Heatmap",
    labels={"color": "Intensity"}
)
fig.update_layout(
    width=1200,
    height=800,
)
fig.show()

"""**4. Based of these graphics we can conclude some given information and create a hypothesis**

During the period from late January to March 2018, the decrease in the price of cryptocurrency is accompanied by a decrease in volatility (the difference between High and Low), which may indicate market stabilization at lower price levels.

To prove or refute this hypothesis we should follow some steps:
- Calculate volatility for each day as the difference between High and Low.
- Construct a graph of volatility versus time.
- Check statistically whether there is a significant decrease in volatility over the period.
- Draw a volatility graph by day and overlay a trend line on it.

1. Let's calulate volatility for each day as a diffeerence between High and Low prices and check statistically whether there is a significant decrease in volatility over the period
"""

df = df.iloc[:50, [1, 2, 3]]
df.columns = ['date', 'low', 'high']
df['date'] = pd.to_datetime(df['date'])
df['low'] = pd.to_numeric(df['low'], errors='coerce')
df['high'] = pd.to_numeric(df['high'], errors='coerce')
df['volatility'] = df['high'] - df['low']
print(df[['date', 'low', 'high', 'volatility']])

"""We created a new dataset with column "Volatility". Now, we can create a graph which presents "Data" and "Volatility"
"""

fig = px.line(df, x='date', y='volatility', labels={'volatility': 'Volatility', 'date': 'Data'})
fig.show()

"""Now we should check statitically whether there is a significant decrease in volatility over the period. For do this, we should divide the data into two halves,
calculate for each half.
"""

data_frame = df.iloc[:50, [1, 2, 3]]
data_frame.columns = ['date', 'low', 'high']
data_frame['date'] = pd.to_datetime(data_frame['date'], errors='coerce')
data_frame['low'] = pd.to_numeric(data_frame['low'], errors='coerce')
data_frame['high'] = pd.to_numeric(data_frame['high'], errors='coerce')
data_frame.dropna(inplace=True)
data_frame['volatility'] = data_frame['high'] - data_frame['low']
#print(df[['date', 'low', 'high', 'volatility']])
n = len(data_frame)
half = n // 2
first_half_volatility = data_frame['volatility'][:half]
second_half_volatility = data_frame['volatility'][half:]
mean_first_half = np.mean(first_half_volatility)
mean_second_half = np.mean(second_half_volatility)
absolute_change = mean_first_half - mean_second_half
print(f'Average volatility of the first half:: {mean_first_half}')
print(f'Average volatility of the second half: {mean_second_half}')
print(f'Absolute reduction of volatility: {absolute_change}')
threshold = 0.01
if absolute_change > threshold:
    print("Dramatic volatility")
else:
    print("Smooth volatility")

data_frame = df.iloc[:, [1, 2, 3]].copy()
data_frame.columns = ['date', 'low', 'high']
data_frame['date'] = pd.to_datetime(data_frame['date'], errors='coerce')
data_frame['low'] = pd.to_numeric(data_frame['low'], errors='coerce')
data_frame['high'] = pd.to_numeric(data_frame['high'], errors='coerce')
data_frame.dropna(inplace=True)
if data_frame['date'].isnull().any():
    raise ValueError("There are invalid dates in the DataFrame.")
data_frame['volatility'] = data_frame['high'] - data_frame['low']
data_frame = data_frame[(data_frame['date'] >= '2018-01-30') & (data_frame['date'] <= '2018-03-20')]
fig = go.Figure()
fig.add_trace(go.Scatter(x=data_frame['date'], y=data_frame['volatility'],
                         mode='lines+markers', name='Daily Volatility',
                         line=dict(color='blue')))
ordinal_dates = data_frame['date'].map(pd.Timestamp.toordinal)
z = np.polyfit(ordinal_dates, data_frame['volatility'], 1)
p = np.poly1d(z)
fig.add_trace(go.Scatter(x=data_frame['date'], y=p(ordinal_dates),
                         mode='lines', name='Trend Line',
                         line=dict(color='red', dash='dash')))
fig.update_layout(template='plotly_white')
fig.show()

"""Thus, it can be argued that although cryptocurrency prices have been declining, volatility has fluctuated, which may mean that the cryptocurrency market continues to be subject to volatility even in the face of declining prices. This is an important observation that can help traders and investors make informed decisions.

**5. Add some important columns to our project, which can be helpful to predict volatility more precisely**
"""

df['Average Price'] = (df['High'] - df['Low']) / 2
df['Daily Price Change'] = df['Average Price'].diff().round(2)
df.dropna(inplace=True)
print(df)

"""**Average Price** - the average price is calculated as the average value between the maximum  and minimum prices for a certain period. This allows you to smooth out the sharp fluctuations that can be observed if you look only at the high or low prices.

**Daily Price Change** - it allows you to quickly identify anomalies and abrupt changes, which is especially useful for traders and analysts seeking to identify volatile periods. For example, if a price change exceeds a certain threshold, it may signal high volatility on that day.

***6. Conclusion:***

In my project, I analyzed the dataset, built graphs based on the data provided, and also hypothesized about changes in cryptocurrency prices and added several new elements to simplify the analysis in the future.
"""